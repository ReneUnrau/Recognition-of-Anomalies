latitude <- as.numeric((coordinates[i,2]))
longitude <- as.numeric((coordinates[i,1]))
# REMOVE LOOP AFTER PRESENTATION!!
for (i in 1:10){
#map$addCircle(latitude, longitude, 5, options = list(color = '#ff0000'))
}
}
indices
}
findOutliers(tr1)
findOutliers = function (track, map) {
# TO DO -> make function generice, add function to renes drawer function, add checkbox for visualization of anomalies
data = track@data$Throttle.Position
ex_low = c()
ex_high = c()
# Calculate lower and higher border of whiskers
lower_border <- quantile(data, probs=0.25) - (1.5*IQR(data)) #Lower border for extremes
upper_border <- quantile(data, probs=0.75) + (1.5*IQR(data)) #Upper border for extremes
# Get values of outliers
lows <- data[data<lower_border] #High extremes
highs <- data[data>upper_border] #Low extremes
# Get indices corresponding to those outliers
indices_low <- which(data<lower_border)
indices_high <- which(data>upper_border)
# Merge indices to single array
indices <- c(indices_low,indices_high)
indices
# Draw corresponding points on Map
coordinates = track@sp@coords
for(i in indices){
latitude <- as.numeric((coordinates[i,2]))
longitude <- as.numeric((coordinates[i,1]))
# REMOVE LOOP AFTER PRESENTATION!!
for (i in 1:10){
#map$addCircle(latitude, longitude, 5, options = list(color = '#ff0000'))
}
}
indices
}
findOutliers(tr1)
findOutliers = function (track, attr, map) {
data <- switch(attr,
"Co2" = track@data$Co2,
"Calculated.MAF" = track@data$Calculated.MAF,
"Engine.Load" = track@data$Engine.Load,
"GPS.Accuracy" = track@data$GPS.Accuracy)
# TO DO -> make function generice, add function to renes drawer function, add checkbox for visualization of anomalies
#data = track@data$Throttle.Position
ex_low = c()
ex_high = c()
# Calculate lower and higher border of whiskers
lower_border <- quantile(data, probs=0.25) - (1.5*IQR(data)) #Lower border for extremes
upper_border <- quantile(data, probs=0.75) + (1.5*IQR(data)) #Upper border for extremes
# Get values of outliers
lows <- data[data<lower_border] #High extremes
highs <- data[data>upper_border] #Low extremes
# Get indices corresponding to those outliers
indices_low <- which(data<lower_border)
indices_high <- which(data>upper_border)
# Merge indices to single array
indices <- c(indices_low,indices_high)
indices
# Draw corresponding points on Map
coordinates = track@sp@coords
for(i in indices){
latitude <- as.numeric((coordinates[i,2]))
longitude <- as.numeric((coordinates[i,1]))
# REMOVE LOOP AFTER PRESENTATION!!
for (i in 1:10){
#map$addCircle(latitude, longitude, 5, options = list(color = '#ff0000'))
}
}
indices
}
findOutliers(tr1, "Co2")
findOutliers(tr1, "GPS.Accuracy")
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
a = c(1,2,3,4,5,6,7,8,9,10)
b = c(1,3,5,7,9)
c = c(4,4,7,2,23)
a
b
c
var(a)
sd(a)
plot(a)
plot(sd(a)
selectInput("tracksList",
plot(sd(a))
plot a
plot (a)
var(c)
sd(c)
d = (2,4,6)
d = c(2,4,6)
var(d)
sd(2)
sd(d)
e = c(2,4,6, 8, 10)
f = c(2,4,6, 8, 11)
var(e)
var(f)
sd(e)
se(f)
sd(f)
vac = c(1,3,7)
vac = c(1,3,8)
var(vac)
?exp
?var
mean(1:10)
(1-5.5)^2+(2-5.5)^2+(3-5.5)^2+(4-5.5)^2+(5-5.5)^2+(6-5.5)^2+(7-5.5)^2+(8-5.5)^2+(9-5.5)^2+(10-5.5)^2
((1-5.5)^2)*0.1+((2-5.5)^2)*0.1+((3-5.5)^2)*0.1+((4-5.5)^2)*0.1+((5-5.5)^2)*0.1+((6-5.5)^2)*0.1+((7-5.5)^2)*0.1+((8-5.5)^2)*0.1+((9-5.5)^2)*0.1+((10-5.5)^2)*0.1
var(1:10)
((1-5.5)^2)*0.1+((2-5.5)^2)*0.2+((3-5.5)^2)*0.3+((4-5.5)^2)*0.4+((5-5.5)^2)*0.5+((6-5.5)^2)*0.4+((7-5.5)^2)*0.1+((8-5.5)^2)*0.1+((9-5.5)^2)*0.1+((10-5.5)^2)*0.1
((1-5.5)^2)*0.1+((2-5.5)^2)*0.2+((3-5.5)^2)*0.3+((4-5.5)^2)*0.4+((5-5.5)^2)*0.5+((6-5.5)^2)*0.4+((7-5.5)^2)*0.3+((8-5.5)^2)*0.2+((9-5.5)^2)*0.1+((10-5.5)^2)*0.1
((1-5.5)^2)*0.1+((2-5.5)^2)*0.1+((3-5.5)^2)*0.1+((4-5.5)^2)*0.1+((5-5.5)^2)*0.1+((6-5.5)^2)*0.1+((7-5.5)^2)*0.1+((8-5.5)^2)*0.1+((9-5.5)^2)*0.1+((10-5.5)^2)*0.1
((1-5.5)^2+(2-5.5)^2+(3-5.5)^2+(4-5.5)^2+(5-5.5)^2+(6-5.5)^2+(7-5.5)^2+(8-5.5)^2+(9-5.5)^2+(10-5.5)^2)/10
1*0.333+3*0.333+8*0.333
var(1:10)
1+2+3+4+5+6+7+8+9+10
55/10
(1-5.5)^2+(2-5.5)^2+(3-5.5)^2+(4-5.5)^2+(5-5.5)^2+(6-5.5)^2+(7-5.5)^2+(8-5.5)^2+(9-5.5)^2+(10-5.5)^2
sqrt(82.5)
sd(1:10)
a = c(1,4,6)
var(a)
11/3
(1-3.6666)^2+(4-3.6666)^2+(6-3.6666)^2
12.6666/3
#' Imports the envirocar data
#'
#' @param serverUrl url to server
#' @param trackIDs ids of tracks that should be retrieved
#' @param bbox spatial bounding box as defined in package sp (matrix with two columns min and max)
#' @param timeInterval interval (list of POSIXct objects)
#' @return Tracks objects for the requested tracks
#'
#'
importEnviroCar = function(serverUrl, trackIDs, bbox, timeInterval, limit = 50) {
# query track IDs for bounding box and time interval; if trackIDs paramter is set, bbox and timeInterval are ignored
if (missing(trackIDs)){
trackIDs = getTrackIDs(serverUrl,bbox,timeInterval, limit)
}
# query track for each trackID
if(length(trackIDs)==0)
stop("No tracks available for the specified boundingbox and/or temporal filter.")
tracks = TracksCollection(lapply(trackIDs,importSingleTrack,serverUrl=serverUrl))
return(tracks)
}
#' Imports a single track
#'
#' @param serverUrl url to server
#' @param trackID ids of the track that should be retrieved
#' @param verbose print debug output
#' @return Tracks objects for the requested tracks
#'
#'
importSingleTrack <- function(serverUrl, trackID, verbose = FALSE){
singleTrackUrl=paste(serverUrl,"/tracks/",trackID,sep="")
if(verbose)message(paste("Retrieving single track from url ",singleTrackUrl,sep=""))
# read data as spatial object:
layer = readOGR(getURL(singleTrackUrl,ssl.verifypeer = FALSE), layer = "OGRGeoJSON")
# convert time from text to POSIXct:
layer$time = as.POSIXct(layer$time, format="%Y-%m-%dT%H:%M:%SZ")
# the third column is JSON, we want it in a table (data.frame) form:
# 1. form a list of lists
l1 = lapply(as.character(layer[[3]]), fromJSON)
# 2. parse the $value elements in the sublist:
l2 = lapply(l1,
function(x) as.data.frame(lapply(x, function(X) X$value)))
# create a matrix with all columns and then convert it to a data frame
# thanks to Kristina Helle!
# dynamic parsing of phenomenon names and units
phenomenonsUrl = paste(serverUrl,"/phenomenons",sep="")
phenomenons = fromJSON(getURL(phenomenonsUrl,ssl.verifypeer = FALSE))
colNames = str_replace_all(sapply(phenomenons[[1]], "[[", "name"),
pattern = " ",
replacement = ".")
colNames = str_replace_all(colNames, pattern = "-", replacement = ".")
resultMatrix = matrix(nrow=length(l2),ncol=length(colNames))
dimnames(resultMatrix)[[2]]=colNames
for (i in seq(along = l2))
resultMatrix[i,names(l2[[i]])]=as.numeric(l2[[i]])
result = as.data.frame(resultMatrix)
# set the units:
units <- sapply(phenomenons[[1]], "[[", "unit")
names(units)=colNames
layer[[3]] = NULL
# add the table as attributes to the spatial object
if (length(layer) == nrow(result)) {
layer = spCbind(layer, result)
stidf = STIDF(geometry(layer), layer$time, layer@data)
#filtering of duplicate measurements in a single track
redundant = which(diff(as.numeric(index(stidf@time)))==0)
if(length(redundant)!=0){
stidf = stidf[-redundant,]
}
track = Track(stidf)
attr(track, "units") = units
tracks = Tracks(list(track)) #TODO: group single tracks
return(tracks)
} else
NULL
}
#' retrieves the track IDs from the Envirocar server for passed spatial and/or temporal filter
#'
#' @param serverUrl base URL of the Envirocar server
#' @param bbox spatial bounding box
#' @param timeInterval interval represented as list of POSIXct
#' @param verbose print debug output
#' @return list containing the track IDs for the specified bbox and time interval, if these are present; otherwise all track IDs are returned
#'
#'
getTrackIDs <- function(serverUrl, bbox, timeInterval, limit = 50, verbose = FALSE){
trackUrl = paste(serverUrl,"/tracks",sep="")
#add bbox parameter to URL, if present
if (!missing(bbox)){
bboxParam = paste("?bbox=", bbox[1,1], ",", bbox[2,1], ",", bbox[1,2], ",",
bbox[2,2], sep = "")
trackUrl = paste(trackUrl, bboxParam, sep = "")
}
#add timeInterval parameter to URL, if present
if (!missing(timeInterval)){
isoFormat="%Y-%m-%dT%H:%M:%SZ"
timeParam = paste("during=",format(timeInterval$first.time,format=isoFormat),",",format(timeInterval$last.time,format=isoFormat),sep="")
if(missing(bbox)) trackUrl= paste(trackUrl,"?",sep="") # add '?', if bbox parameter is missing
else trackUrl= paste(trackUrl,"&",sep="") # if bbox is there, add '&' for seperating parameters
trackUrl = paste(trackUrl,timeParam,sep="")
}
#add limit parameter to URL, if not set the default parameter is used
if (!missing(limit)){
limitParam = paste("&limit=",limit,sep="")
trackUrl = paste(trackUrl,limitParam,sep="")
}
if (verbose) message(paste("Basic track url is ",trackUrl))
#set header parameter to retrieve header; passing header function as in RCurl example doesn't work
body = getURI(trackUrl,ssl.verifypeer=FALSE,header=1)
#split header from body and select header string
headerAndBody = strsplit(body, split="\r\n\r\n")
headerString = headerAndBody[[1]][1]
body = headerAndBody[[1]][2]
#if(verbose) message(paste("Header is :",headerString))
###################
# Do not load more then 100 tracks!! Due to performance reasons!
###################
#######################
#check whether there are more than 100 entries (then paging is needed!)
#header = parseHTTPHeader(headerString)
#result = lapply(header,parseLinkHeaderParam)
#result <- result[!sapply(result,is.null)] #remove null items
#pagenumber=0
#if (length(result)>0){
#  for (i in 1:length(result)){
#    if (grepl("last",result[i]$Link["relation"])){
#      pagenumber = as.numeric(result[i]$Link["pagenumber"])
#      if(verbose)message(paste("Number of pages for paging is ",pagenumber))
#    }
#  }
#}
#parsing of actual track IDs, if paging is true (pagenumber>0), repeat parsing for each page
trackIDs = parseTrackIDs(body)
#if(pagenumber>1){
#  for (i in 2:pagenumber){
#    if(verbose)message(paste("Iterating page ", i))
#    paramString = paste ("limits=100&page=",i,sep="")
#    if (missing(bbox)&&missing(timeInterval))requestUrl=paste(trackUrl,"?",paramString,sep="")
#    else requestUrl=paste(trackUrl,"&",paramString,sep="")
#    body = getURI(requestUrl,ssl.verifypeer=FALSE)
#    currentTracks = parseTrackIDs(body)
#    if(verbose)message(paste("Current number of tracks ", length(currentTracks)," for request url ",requestUrl))
#    trackIDs = c(trackIDs,currentTracks)
#  }
#}
return(trackIDs)
}
#' ugly function for parsing the Link header parameter from the HTTP header, used for the paging mechanism
#'
#' @param headerParam url to server
#' @return Tracks objects for the requested tracks
#'
#'
parseLinkHeaderParam <- function(headerParam){
if (grepl("rel=",headerParam)){
#link parameter looks like
#<https://envirocar.org/api/stable/tracks?limit=100&page=1>;rel=first;type=application/json
lastpart=strsplit(headerParam,"&page=")[[1]][2] #split string by page parameter in order to retrieve page number and type of relation (rel)
lastpartSplitted=strsplit(lastpart,"[>]")[[1]]
pageNumberString = strsplit(lastpartSplitted[1],"&")[[1]][1] #needed, if there are additional bbox or time parameter
rel = strsplit(strsplit(lastpartSplitted[2],"rel=")[[1]][2],";type")[[1]][1]
result = c(pagenumber=pageNumberString,relation=rel)
return(result)
}
else
return(NULL)
}
#' function that is used internally for parsing the trackIDs from JSON response
#'
#' @param jsonBody that is return for a tracks URL from Envirocar server
#' @return list containing the parsed trackIDs
#'
parseTrackIDs<-function(jsonBody){
#sapply(fromJSON(jsonBody)$tracks,function(x) return(x$id))
#sapply(fromJSON(jsonBody)$tracks,function(x) return(x["id"]))
sapply(fromJSON(jsonBody)$tracks,function(x) return(x[["id"]]))
}
## Work with car data
# test to call function from another file
source("import.R")
require(rgdal)
require(RCurl)
require(RJSONIO)
require(stringr)
require(maptools)
require(spacetime)
require(trajectories)
require(sp)
stableURL = "https://envirocar.org/api/stable"
trackID = "545aa4f4e4b0b53890a2e62c"
# get single track
queryTracksCollection = importEnviroCar(stableURL, trackID)
## get the measurements
measurements = queryTracksCollection@tracksCollection$Tracks1@tracks$Track1@data
head(measurements)
## get the points
queryPoints = queryTracksCollection@tracksCollection$Tracks1@tracks$Track1@sp
## plot the points of the track
plot(queryPoints@coords, col="green")
## weekday filter (just some testing)
d = as.Date("2014-11-13")
# function to get the weekday from a date
printWeekday = function(date){
weekdayNumber = as.POSIXlt(date)$wday # get the number of the weekday
weekdays = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
weekdays[weekdayNumber]
}
print(printWeekday(d))
# testing bbox
ll = c(7.6,51.95) # lower left : 51.928179, 7.573629
ur = c(7.65,52) # upper right: 51.985515, 7.674909
boundingbox = matrix(c(ll, ur),ncol=2,dimnames=list(c("x","y"),c("min","max")))
boundingbox
# disable timeouts
setInternet2(use=NA)
setInternet2(use=FALSE)
setInternet2(use=NA)
#queryBoundingBox = importEnviroCar(serverUrl=stableURL, bbox=boundingbox) # loads all tracks from boundingbox
# get trackIDs from bbox
trIds = getTrackIDs(serverUrl=stableURL, bbox=boundingbox)
trIds
# just get the first 5 IDs
tr5 = trIds[1:5]
tr5
trCol5 = importEnviroCar(serverUrl = stableURL, trackIDs = tr5) # track 1 and 2 seem to be identical
plot(trCol5@tracksCollection$Tracks1@tracks$Track1@sp@coords, type="l", col="red")
lines(trCol5@tracksCollection$Tracks3@tracks$Track1@sp@coords, type="l", col="blue")
lines(trCol5@tracksCollection$Tracks4@tracks$Track1@sp@coords, type="l", col="green")
lines(trCol5@tracksCollection$Tracks5@tracks$Track1@sp@coords, type="l", col="yellow")
# get number of tracks in trackscollection
length(trCol5@tracksCollection)
trIdsTestLimit = getTrackIDs(serverUrl=stableURL, bbox=boundingbox, limit=5, verbose=T)
trIdsTestLimit
# test timeinterval
start = as.POSIXct(x = "2015-01-01")
end = as.POSIXct(x = "2015-01-12")
time_interval = c(start, end)
trIdsTestTimeLimit = getTrackIDs(serverUrl=stableURL, timeInterval = time_interval, limit=5, verbose=T)
trIdsTestTimeLimit
# get the tracknumber from a trackname (i.e. "track 1" -> 1)
get_trackNumber = function(trackname){
trackname = toupper(trackname)
return(as.numeric(gsub("TRACK", "", trackname)))
}
# test function
tr_num = get_trackNumber("Track2")
# select a track from TracksCollection
get_track = function(tracksCollection, tracknumber){
return(tracksCollection[tracknumber][1])
}
# test if tracks work
tr1 = get_track(trCol5, 1)
tr2 = get_track(trCol5, 2)
plot(tr1@sp@coords, type="l", col="red")
lines(tr2@sp@coords, type="l", col="blue")
tr1@connections$speed[1]
tr2@connections$speed[1]
# Functions
findOutliers = function (track, attr, map) {
# TO DO ->add function to renes drawer function, add checkbox for visualization of anomalies
data <- switch(attr,
"Co2" = track@data$Co2,
"Calculated.MAF" = track@data$Calculated.MAF,
"Engine.Load" = track@data$Engine.Load,
"GPS.Accuracy" = track@data$GPS.Accuracy,
"GPS.HDOP" = track@data$GPS.HDOP,
"GPS.PDOP" = track@data$GPS.PDOP,
"GPS.Speed" = track@data$GPS.Speed,
"GPS.VDOP" = track@data$GPS.VDOP,
"Intake.Pressure" = track@data$Intake.Pressure,
"Intake.Temperature" = track@data$Intake.Temperature,
"MAF" = track@data$MAF,
"Rpm" = track@data$Rpm,
"Speed" = track@data$Speed,
"Throttle.Position" = track@data$Throttle.Position)
ex_low = c()
ex_high = c()
# Calculate lower and higher border of whiskers
lower_border <- quantile(data, probs=0.25) - (1.5*IQR(data)) #Lower border for extremes
upper_border <- quantile(data, probs=0.75) + (1.5*IQR(data)) #Upper border for extremes
# Get values of outliers
lows <- data[data<lower_border] #High extremes
highs <- data[data>upper_border] #Low extremes
# Get indices corresponding to those outliers
indices_low <- which(data<lower_border)
indices_high <- which(data>upper_border)
# Merge indices to single array
indices <- c(indices_low,indices_high)
indices
print("Number of outliers:")
print(length(indices))
# show track on map
tr_coordinates = track@sp@coords
map$clearShapes()
for(i in 1:nrow(tr_coordinates)){
latitude <- as.numeric((tr_coordinates[i,2]))
longitude <- as.numeric((tr_coordinates[i,1]))
map$addCircle(latitude, longitude, 5)
}
# Draw corresponding points on Map
coordinates = track@sp@coords
for(i in indices){
latitude <- as.numeric((coordinates[i,2]))
longitude <- as.numeric((coordinates[i,1]))
# REMOVE LOOP AFTER PRESENTATION!!
for (i in 1:10){
map$addCircle(latitude, longitude, 5, options = list(color = '#ff0000'))
}
}
}
findOutliers(tr1)
setwd("D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/loadTracks")
source("import.R")
tr1 = get_track(trCol5, 1)
tr1@data$GPS.SPeed
tr1@data$GPS.Speed
tr1@data$Speed
tr1@data$GPS.Speed[1,]
tr1@data$GPS.Speed[,1]
tr1@data$GPS.Speed[1]
tr1@data$GPS.Speed[1:20]
tr1@data$Speed[1:20]
tr1@connections
tr1@connections[1]
tr1@connections[,1]
tr1@connections[1,]
tr1@connections.speed
tr1@connections$speed
tr1@data$GPS.Speed[1:20]
tr1@data$Speed[1:20]
tr1@connections$speed[1:20]
tr1@connections$speed[2507]
gps = tr1@data$GPS.Speed[1:20]
reg = tr1@data$Speed[1:20]
con = tr1@connections$speed[2507]
plot(gps)
plot(gps, type = "l")
lines(reg, col="green")
lines(con, col="red")
con = tr1@connections$speed[1:20]
lines(con, col="red")
x = c(3,8)
var(x)
11/2
((3-5.5)^2 + (8 - 5.5)^2 ) / 2
((3-5.5)^2 + (8 - 5.5)^2 )
((3-5.5)^2)*0.5 + ((8 - 5.5)^2)*0.5
var(reg, gps)
(reg[1], gps[1])
var(reg[1], gps[1])
reg[1]
gps[1]
var(reg[1], gps[1])
var(c(reg[1], gps[1])
)
mean(reg[1], gps[1])
mean(c(reg[1], gps[1])
)
a
b
c(a,b)
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
var(c(46,43))
var(c(46.855,43.245))
var(c(46.855,43.245))
diff(2,4)
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
shiny::runApp('D:/Dropbox/Universität/Master/WS 2014-2015/AOFCD/Project/Recognition-of-Anomalies/shiny/fcd')
